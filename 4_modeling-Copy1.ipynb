{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll try to create a model which can predict a better results.<br>\n",
    "**Better results** ==\n",
    "1. The model should predict as many churned customers as possible.\n",
    "2. FN (False Negative) must be low\n",
    "3. Recall is important here and must be high\n",
    "* If model's F1 score is high, then the model is doing well all around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for modeling\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "#import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# if we want to see all columns, we set this parametr on\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# use custom function\n",
    "%run -i 'py/dataframecheck.py'\n",
    "\n",
    "# set style for plots\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df = pd.read_csv(\"data/mod_churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the dataset for modeling, we need to encode categorical features to numbers. This means encoding \"Yes\", \"No\" to 0 and 1 so that algorithm can work with the data. This process is called onehot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define caterogical columns and numeric columns\n",
    "cat_cols=['gender', 'seniorcitizen', 'partner', 'dependents',\n",
    "       'phoneservice', 'multiplelines', 'internetservice', 'onlinesecurity',\n",
    "       'onlinebackup', 'deviceprotection', 'techsupport', 'streamingtv',\n",
    "       'streamingmovies', 'contract', 'paperlessbilling', 'paymentmethod']\n",
    "numeric_cols=['tenure','monthlycharges', 'totalcharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seniorcitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>monthlycharges</th>\n",
       "      <th>totalcharges</th>\n",
       "      <th>churn</th>\n",
       "      <th>partner_No</th>\n",
       "      <th>partner_Yes</th>\n",
       "      <th>dependents_No</th>\n",
       "      <th>dependents_Yes</th>\n",
       "      <th>multiplelines_No</th>\n",
       "      <th>multiplelines_No phone service</th>\n",
       "      <th>multiplelines_Yes</th>\n",
       "      <th>internetservice_DSL</th>\n",
       "      <th>internetservice_Fiber optic</th>\n",
       "      <th>internetservice_No</th>\n",
       "      <th>onlinebackup_No</th>\n",
       "      <th>onlinebackup_No internet service</th>\n",
       "      <th>onlinebackup_Yes</th>\n",
       "      <th>deviceprotection_No</th>\n",
       "      <th>deviceprotection_No internet service</th>\n",
       "      <th>deviceprotection_Yes</th>\n",
       "      <th>techsupport_No</th>\n",
       "      <th>techsupport_No internet service</th>\n",
       "      <th>techsupport_Yes</th>\n",
       "      <th>streamingtv_No</th>\n",
       "      <th>streamingtv_No internet service</th>\n",
       "      <th>streamingtv_Yes</th>\n",
       "      <th>contract_Month-to-month</th>\n",
       "      <th>contract_One year</th>\n",
       "      <th>contract_Two year</th>\n",
       "      <th>paperlessbilling_No</th>\n",
       "      <th>paperlessbilling_Yes</th>\n",
       "      <th>paymentmethod_Bank transfer (automatic)</th>\n",
       "      <th>paymentmethod_Credit card (automatic)</th>\n",
       "      <th>paymentmethod_Electronic check</th>\n",
       "      <th>paymentmethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7032 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seniorcitizen  tenure  monthlycharges  totalcharges  churn  partner_No  partner_Yes  dependents_No  dependents_Yes  multiplelines_No  multiplelines_No phone service  multiplelines_Yes  internetservice_DSL  internetservice_Fiber optic  internetservice_No  onlinebackup_No  onlinebackup_No internet service  onlinebackup_Yes  deviceprotection_No  deviceprotection_No internet service  deviceprotection_Yes  techsupport_No  techsupport_No internet service  techsupport_Yes  streamingtv_No  streamingtv_No internet service  streamingtv_Yes  contract_Month-to-month  contract_One year  contract_Two year  paperlessbilling_No  paperlessbilling_Yes  paymentmethod_Bank transfer (automatic)  paymentmethod_Credit card (automatic)  paymentmethod_Electronic check  paymentmethod_Mailed check\n",
       "0                 0       1           29.85         29.85      0           0            1              1               0                 0                               1                  0                    1                            0                   0                0                                 0                 1                    1                                     0                     0               1                                0                0               1                                0                0                        1                  0                  0                    0                     1                                        0                                      0                               1                           0\n",
       "1                 0      34           56.95       1889.50      0           1            0              1               0                 1                               0                  0                    1                            0                   0                1                                 0                 0                    0                                     0                     1               1                                0                0               1                                0                0                        0                  1                  0                    1                     0                                        0                                      0                               0                           1\n",
       "2                 0       2           53.85        108.15      1           1            0              1               0                 1                               0                  0                    1                            0                   0                0                                 0                 1                    1                                     0                     0               1                                0                0               1                                0                0                        1                  0                  0                    0                     1                                        0                                      0                               0                           1\n",
       "3                 0      45           42.30       1840.75      0           1            0              1               0                 0                               1                  0                    1                            0                   0                1                                 0                 0                    0                                     0                     1               0                                0                1               1                                0                0                        0                  1                  0                    1                     0                                        1                                      0                               0                           0\n",
       "4                 0       2           70.70        151.65      1           1            0              1               0                 1                               0                  0                    0                            1                   0                1                                 0                 0                    1                                     0                     0               1                                0                0               1                                0                0                        1                  0                  0                    0                     1                                        0                                      0                               1                           0\n",
       "...             ...     ...             ...           ...    ...         ...          ...            ...             ...               ...                             ...                ...                  ...                          ...                 ...              ...                               ...               ...                  ...                                   ...                   ...             ...                              ...              ...             ...                              ...              ...                      ...                ...                ...                  ...                   ...                                      ...                                    ...                             ...                         ...\n",
       "7027              0      24           84.80       1990.50      0           0            1              0               1                 0                               0                  1                    1                            0                   0                1                                 0                 0                    0                                     0                     1               0                                0                1               0                                0                1                        0                  1                  0                    0                     1                                        0                                      0                               0                           1\n",
       "7028              0      72          103.20       7362.90      0           0            1              0               1                 0                               0                  1                    0                            1                   0                0                                 0                 1                    0                                     0                     1               1                                0                0               0                                0                1                        0                  1                  0                    0                     1                                        0                                      1                               0                           0\n",
       "7029              0      11           29.60        346.45      0           0            1              0               1                 0                               1                  0                    1                            0                   0                1                                 0                 0                    1                                     0                     0               1                                0                0               1                                0                0                        1                  0                  0                    0                     1                                        0                                      0                               1                           0\n",
       "7030              1       4           74.40        306.60      1           0            1              1               0                 0                               0                  1                    0                            1                   0                1                                 0                 0                    1                                     0                     0               1                                0                0               1                                0                0                        1                  0                  0                    0                     1                                        0                                      0                               0                           1\n",
       "7031              0      66          105.65       6844.50      0           1            0              1               0                 1                               0                  0                    0                            1                   0                1                                 0                 0                    0                                     0                     1               0                                0                1               0                                0                1                        0                  0                  1                    0                     1                                        1                                      0                               0                           0\n",
       "\n",
       "[7032 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seniorcitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>monthlycharges</th>\n",
       "      <th>totalcharges</th>\n",
       "      <th>churn</th>\n",
       "      <th>partner_No</th>\n",
       "      <th>partner_Yes</th>\n",
       "      <th>dependents_No</th>\n",
       "      <th>dependents_Yes</th>\n",
       "      <th>multiplelines_No</th>\n",
       "      <th>multiplelines_No phone service</th>\n",
       "      <th>multiplelines_Yes</th>\n",
       "      <th>internetservice_DSL</th>\n",
       "      <th>internetservice_Fiber optic</th>\n",
       "      <th>internetservice_No</th>\n",
       "      <th>onlinebackup_No</th>\n",
       "      <th>onlinebackup_No internet service</th>\n",
       "      <th>onlinebackup_Yes</th>\n",
       "      <th>deviceprotection_No</th>\n",
       "      <th>deviceprotection_No internet service</th>\n",
       "      <th>deviceprotection_Yes</th>\n",
       "      <th>techsupport_No</th>\n",
       "      <th>techsupport_No internet service</th>\n",
       "      <th>techsupport_Yes</th>\n",
       "      <th>streamingtv_No</th>\n",
       "      <th>streamingtv_No internet service</th>\n",
       "      <th>streamingtv_Yes</th>\n",
       "      <th>contract_Month-to-month</th>\n",
       "      <th>contract_One year</th>\n",
       "      <th>contract_Two year</th>\n",
       "      <th>paperlessbilling_No</th>\n",
       "      <th>paperlessbilling_Yes</th>\n",
       "      <th>paymentmethod_Bank transfer (automatic)</th>\n",
       "      <th>paymentmethod_Credit card (automatic)</th>\n",
       "      <th>paymentmethod_Electronic check</th>\n",
       "      <th>paymentmethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.440296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seniorcitizen    tenure  monthlycharges  totalcharges     churn  partner_No  partner_Yes  dependents_No  dependents_Yes  multiplelines_No  multiplelines_No phone service  multiplelines_Yes  internetservice_DSL  internetservice_Fiber optic  internetservice_No  onlinebackup_No  onlinebackup_No internet service  onlinebackup_Yes  deviceprotection_No  deviceprotection_No internet service  deviceprotection_Yes  techsupport_No  techsupport_No internet service  techsupport_Yes  streamingtv_No  streamingtv_No internet service  streamingtv_Yes  contract_Month-to-month  contract_One year  contract_Two year  paperlessbilling_No  paperlessbilling_Yes  paymentmethod_Bank transfer (automatic)  paymentmethod_Credit card (automatic)  paymentmethod_Electronic check  paymentmethod_Mailed check\n",
       "0      -0.440296 -0.440296       -0.440296     -0.440296 -0.440296   -0.440296    -0.440296      -0.440296       -0.440296         -0.440296                       -0.440296          -0.440296            -0.440296                    -0.440296           -0.440296        -0.440296                         -0.440296         -0.440296            -0.440296                             -0.440296             -0.440296       -0.440296                        -0.440296        -0.440296       -0.440296                        -0.440296        -0.440296                -0.440296          -0.440296          -0.440296            -0.440296             -0.440296                                -0.440296                              -0.440296                       -0.440296                   -0.440296\n",
       "1      -0.440296 -0.440296       -0.440296     -0.440296 -0.440296   -0.440296    -0.440296      -0.440296       -0.440296         -0.440296                       -0.440296          -0.440296            -0.440296                    -0.440296           -0.440296        -0.440296                         -0.440296         -0.440296            -0.440296                             -0.440296             -0.440296       -0.440296                        -0.440296        -0.440296       -0.440296                        -0.440296        -0.440296                -0.440296          -0.440296          -0.440296            -0.440296             -0.440296                                -0.440296                              -0.440296                       -0.440296                   -0.440296\n",
       "2      -0.440296 -0.440296       -0.440296     -0.440296 -0.440296   -0.440296    -0.440296      -0.440296       -0.440296         -0.440296                       -0.440296          -0.440296            -0.440296                    -0.440296           -0.440296        -0.440296                         -0.440296         -0.440296            -0.440296                             -0.440296             -0.440296       -0.440296                        -0.440296        -0.440296       -0.440296                        -0.440296        -0.440296                -0.440296          -0.440296          -0.440296            -0.440296             -0.440296                                -0.440296                              -0.440296                       -0.440296                   -0.440296\n",
       "3      -0.440296 -0.440296       -0.440296     -0.440296 -0.440296   -0.440296    -0.440296      -0.440296       -0.440296         -0.440296                       -0.440296          -0.440296            -0.440296                    -0.440296           -0.440296        -0.440296                         -0.440296         -0.440296            -0.440296                             -0.440296             -0.440296       -0.440296                        -0.440296        -0.440296       -0.440296                        -0.440296        -0.440296                -0.440296          -0.440296          -0.440296            -0.440296             -0.440296                                -0.440296                              -0.440296                       -0.440296                   -0.440296\n",
       "4      -0.440296 -0.440296       -0.440296     -0.440296 -0.440296   -0.440296    -0.440296      -0.440296       -0.440296         -0.440296                       -0.440296          -0.440296            -0.440296                    -0.440296           -0.440296        -0.440296                         -0.440296         -0.440296            -0.440296                             -0.440296             -0.440296       -0.440296                        -0.440296        -0.440296       -0.440296                        -0.440296        -0.440296                -0.440296          -0.440296          -0.440296            -0.440296             -0.440296                                -0.440296                              -0.440296                       -0.440296                   -0.440296"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z-score normalizing: SScaler\n",
    "df_z = df.fillna(value=0) \n",
    "for col in df_z.columns:\n",
    "    df_z[col] = (df - df.mean())/df.std()\n",
    "\n",
    "df_z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we can see this normalization can't be helpfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seniorcitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>monthlycharges</th>\n",
       "      <th>totalcharges</th>\n",
       "      <th>churn</th>\n",
       "      <th>partner_No</th>\n",
       "      <th>partner_Yes</th>\n",
       "      <th>dependents_No</th>\n",
       "      <th>dependents_Yes</th>\n",
       "      <th>multiplelines_No</th>\n",
       "      <th>multiplelines_No phone service</th>\n",
       "      <th>multiplelines_Yes</th>\n",
       "      <th>internetservice_DSL</th>\n",
       "      <th>internetservice_Fiber optic</th>\n",
       "      <th>internetservice_No</th>\n",
       "      <th>onlinebackup_No</th>\n",
       "      <th>onlinebackup_No internet service</th>\n",
       "      <th>onlinebackup_Yes</th>\n",
       "      <th>deviceprotection_No</th>\n",
       "      <th>deviceprotection_No internet service</th>\n",
       "      <th>deviceprotection_Yes</th>\n",
       "      <th>techsupport_No</th>\n",
       "      <th>techsupport_No internet service</th>\n",
       "      <th>techsupport_Yes</th>\n",
       "      <th>streamingtv_No</th>\n",
       "      <th>streamingtv_No internet service</th>\n",
       "      <th>streamingtv_Yes</th>\n",
       "      <th>contract_Month-to-month</th>\n",
       "      <th>contract_One year</th>\n",
       "      <th>contract_Two year</th>\n",
       "      <th>paperlessbilling_No</th>\n",
       "      <th>paperlessbilling_Yes</th>\n",
       "      <th>paymentmethod_Bank transfer (automatic)</th>\n",
       "      <th>paymentmethod_Credit card (automatic)</th>\n",
       "      <th>paymentmethod_Electronic check</th>\n",
       "      <th>paymentmethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115423</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.385075</td>\n",
       "      <td>0.215867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.354229</td>\n",
       "      <td>0.010310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.239303</td>\n",
       "      <td>0.210241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.521891</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seniorcitizen    tenure  monthlycharges  totalcharges  churn  partner_No  partner_Yes  dependents_No  dependents_Yes  multiplelines_No  multiplelines_No phone service  multiplelines_Yes  internetservice_DSL  internetservice_Fiber optic  internetservice_No  onlinebackup_No  onlinebackup_No internet service  onlinebackup_Yes  deviceprotection_No  deviceprotection_No internet service  deviceprotection_Yes  techsupport_No  techsupport_No internet service  techsupport_Yes  streamingtv_No  streamingtv_No internet service  streamingtv_Yes  contract_Month-to-month  contract_One year  contract_Two year  paperlessbilling_No  paperlessbilling_Yes  paymentmethod_Bank transfer (automatic)  paymentmethod_Credit card (automatic)  paymentmethod_Electronic check  paymentmethod_Mailed check\n",
       "0            0.0  0.000000        0.115423      0.001275    0.0         0.0          1.0            1.0             0.0               0.0                             1.0                0.0                  1.0                          0.0                 0.0              0.0                               0.0               1.0                  1.0                                   0.0                   0.0             1.0                              0.0              0.0             1.0                              0.0              0.0                      1.0                0.0                0.0                  0.0                   1.0                                      0.0                                    0.0                             1.0                         0.0\n",
       "1            0.0  0.464789        0.385075      0.215867    0.0         1.0          0.0            1.0             0.0               1.0                             0.0                0.0                  1.0                          0.0                 0.0              1.0                               0.0               0.0                  0.0                                   0.0                   1.0             1.0                              0.0              0.0             1.0                              0.0              0.0                      0.0                1.0                0.0                  1.0                   0.0                                      0.0                                    0.0                             0.0                         1.0\n",
       "2            0.0  0.014085        0.354229      0.010310    1.0         1.0          0.0            1.0             0.0               1.0                             0.0                0.0                  1.0                          0.0                 0.0              0.0                               0.0               1.0                  1.0                                   0.0                   0.0             1.0                              0.0              0.0             1.0                              0.0              0.0                      1.0                0.0                0.0                  0.0                   1.0                                      0.0                                    0.0                             0.0                         1.0\n",
       "3            0.0  0.619718        0.239303      0.210241    0.0         1.0          0.0            1.0             0.0               0.0                             1.0                0.0                  1.0                          0.0                 0.0              1.0                               0.0               0.0                  0.0                                   0.0                   1.0             0.0                              0.0              1.0             1.0                              0.0              0.0                      0.0                1.0                0.0                  1.0                   0.0                                      1.0                                    0.0                             0.0                         0.0\n",
       "4            0.0  0.014085        0.521891      0.015330    1.0         1.0          0.0            1.0             0.0               1.0                             0.0                0.0                  0.0                          1.0                 0.0              1.0                               0.0               0.0                  1.0                                   0.0                   0.0             1.0                              0.0              0.0             1.0                              0.0              0.0                      1.0                0.0                0.0                  0.0                   1.0                                      0.0                                    0.0                             1.0                         0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min-max scaling for normalize columns MinMaxScaler\n",
    "df_m = df.fillna(value=0) \n",
    "for col in df_m.columns:\n",
    "    df_m[col] = (df_m[col] - min(df_m[col]))/ (max(df_m[col]) - min(df_m[col])) \n",
    "\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transformation foe numeric columns\n",
    "#df_l = df.fillna(value=0)\n",
    "\n",
    "#for col in numeric_cols:\n",
    "#    df_l[col] = np.diff(np.log(df_l.loc[col])) \n",
    "\n",
    "#df_l.head() \n",
    "    \n",
    "#    np.diff(np.log(df.price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(model, X_test, y_train, y_hat_train,y_test, y_hat_test):\n",
    "    # Evaluate predictions\n",
    "    print('-'*40)\n",
    "    print('Accuracy score for Training Dataset = ', accuracy_score(y_train, y_hat_train))\n",
    "    print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "    print('-'*40)\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "    print('-'*40)\n",
    "    print('Classification Matrix:')\n",
    "    print(classification_report(y_test, y_hat_test))\n",
    "    \n",
    "    plot_confusion_matrix(model, X_test, y_test,cmap='bone_r')  \n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_hat_test)\n",
    "    print('AUC: {}'.format(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "y=df['churn'].copy()\n",
    "\n",
    "# Define X\n",
    "X = df.drop(columns=['churn'], axis=1)\n",
    "\n",
    "# Split the data into a training and a test set and set stratify=y to help with imbalance data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score:  0.8023462495556346\n",
      "\n",
      "Accuracy Score:  0.7721293992179168\n",
      "\n",
      "Accuracy Score:  0.710273729114824\n",
      "\n",
      "Accuracy Score:  0.7817276928546036\n"
     ]
    }
   ],
   "source": [
    "classifier_list = [ LogisticRegression(solver='lbfgs'),\n",
    "                    KNeighborsClassifier(),\n",
    "                    GaussianNB(priors=None),\n",
    "                    RandomForestClassifier()]\n",
    "\n",
    "for clf in classifier_list:\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    precision = precision_score(y_test, predictions) \n",
    "    recall=recall_score(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    \n",
    "# Precision_score = tp / (tp + fp)\n",
    "# Accuracy_score = (# of correctly assigned rows) / (All rows)\n",
    "\n",
    "    print(#clf, '\\n \\n',classification_report(y_test, predictions), \n",
    "          #'\\n \\nPrecision Score: ' , precision,\n",
    "          #'\\nRecall Score: ' , recall,\n",
    "          '\\nAccuracy Score: ', accuracy)#,\n",
    "          #'\\n\\n----------------------------------------------------------------\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/flatiron/Mod3/dsc-mod-3-project-v2-1-onl01-dtsc-ft-030220/py/dataframecheck.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLR\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.802803\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.014983\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.794035\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.018261\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.766537\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.022790\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mCART\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.730984\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.014947\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mNB\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.752548\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.017705\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "LR: 0.802803 (0.014983)\n",
    "LDA: 0.794035 (0.018261)\n",
    "KNN: 0.766537 (0.022790)\n",
    "CART: 0.730984 (0.014947)\n",
    "NB: 0.752548 (0.017705)\n",
    "SVM: 0.767720 (0.010604)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a logistic regression base model using statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "y=df_m['churn'].copy()\n",
    "\n",
    "# Define X\n",
    "X = df_m.drop(columns=['churn'], axis=1)\n",
    "\n",
    "# Split the data into a training and a test set and set stratify=y to help with imbalance data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/flatiron/Mod3/dsc-mod-3-project-v2-1-onl01-dtsc-ft-030220/py/dataframecheck.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create intercept term required for sm.Logit, see documentation for more information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sm' is not defined"
     ]
    }
   ],
   "source": [
    "# define y\n",
    "y=df_m['churn'].copy()\n",
    "\n",
    "# Define X\n",
    "X = df_m.drop(columns=['churn'], axis=1)\n",
    "\n",
    "# Create intercept term required for sm.Logit, see documentation for more information\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit model\n",
    "logit_model = sm.Logit(y, X)\n",
    "\n",
    "# Get results of the fit\n",
    "result = logit_model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling with LogesticREgression\n",
    "#create an instance and fit the model \n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "y_hat_train=logmodel.predict(X_train)\n",
    "y_hat_test = logmodel.predict(X_test)\n",
    "\n",
    "evaluate_predictions(logmodel, X_test, y_train, y_hat_train,y_test, y_hat_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try SMOTE for normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original class distribution: \\n')\n",
    "print(y.value_counts())\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train) \n",
    "# Preview synthetic sample class distribution\n",
    "print('-----------------------------------------')\n",
    "print('Synthetic sample class distribution: \\n')\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#predictions\n",
    "y_hat_train=logmodel.predict(X_train_resampled)\n",
    "y_hat_test = logmodel.predict(X_test)\n",
    "\n",
    "evaluate_predictions(logmodel, X_test, y_train_resampled, y_hat_train,y_test, y_hat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')\n",
    "logmodel.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#predictions\n",
    "y_hat_train=logmodel.predict(X_train_resampled)\n",
    "y_hat_test = logmodel.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train_resampled, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_hat_test)\n",
    "print('AUC: {}'.format(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the weights of all the variables\n",
    "weights_LogReg = pd.Series(logmodel.coef_[0], index=X.columns.values)\n",
    "print(weights_LogReg)\n",
    "plt.figure(figsize=(6, 15))\n",
    "weights_LogReg.sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some variables are negatively correlated with the predicted variable (Churn), while some have positively. Negative correlation means that likeliness of churn decreases with that variable.<br>\n",
    "Let me interpret some findings from above plot:<br>\n",
    "As we have seen in our EDA, having a 2 month contract reduces chances of churn. 2 month contract along with tenure have the most negative relation with Churn as predicted by logistic regressions. Total charges, monthly contracts, fibre optic internet services and seniority can lead to higher churn rates. This is interesting because although fibre optic services are faster, customers are likely to churn because of it. I don't understad why this is happening.<br>\n",
    "Till the time let's have a look at other algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Using SMOTE we can improve our score\n",
    "__________\n",
    "\n",
    "## Try to Decision Tree Model\n",
    "Our dayta set nas a lot of Binary columns (0/1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling with Decision Tree\n",
    "#create an instance and fit the model \n",
    "treemodel = DecisionTreeClassifier(random_state=123)\n",
    "treemodel.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "y_hat_train= treemodel.predict(X_train)\n",
    "y_hat_test = treemodel.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score for Training Dataset =  0.9992889310263096 >> then Accuracy score for Testing Dataset =  0.7163170991823676 \n",
    "It show us oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original class distribution: \\n')\n",
    "print(y.value_counts())\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train) \n",
    "# Preview synthetic sample class distribution\n",
    "print('-----------------------------------------')\n",
    "print('Synthetic sample class distribution: \\n')\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treemodel = DecisionTreeClassifier(random_state=123)\n",
    "treemodel.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#predictions\n",
    "y_hat_train=treemodel.predict(X_train_resampled)\n",
    "y_hat_test = treemodel.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train_resampled, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The same ploblem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randommodel = RandomForestClassifier(random_state=123)\n",
    "randommodel.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "y_hat_train=randommodel.predict(X_train_resampled)\n",
    "y_hat_test = randommodel.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train_resampled, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "param_grid = {\n",
    "     'criterion':['gini','entropy'],\n",
    "    'max_depth':[2,3,4,5,20],\n",
    "    'min_samples_split':[5,20,50],\n",
    "    'min_samples_leaf':[15,20,30],\n",
    "    'n_estimators': [1,5,10]\n",
    "}\n",
    "gs = GridSearchCV(rfc, param_grid, cv=3, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 'n_estimators': [1,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(criterion='entropy', random_state=44, min_samples_leaf = 20, min_samples_split = 20, max_depth = 20,n_estimators=10)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "y_hat_train=rfc.predict(X_train)\n",
    "y_hat_test = rfc.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(criterion='entropy', random_state=44, min_samples_leaf = 3, min_samples_split = 10, max_depth = None)\n",
    "rfc.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "y_hat_train=rfc.predict(X_train_resampled)\n",
    "y_hat_test = rfc.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train_resampled, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svcmodel = SVC(gamma='auto')\n",
    "svcmodel.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "y_hat_train= svcmodel.predict(X_train_resampled)\n",
    "y_hat_test = svcmodel.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train_resampled, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original class distribution: \\n')\n",
    "print(y.value_counts())\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train) \n",
    "# Preview synthetic sample class distribution\n",
    "print('-----------------------------------------')\n",
    "print('Synthetic sample class distribution: \\n')\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svcmodel = SVC(gamma='auto')\n",
    "svcmodel.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#predictions\n",
    "y_hat_train= svcmodel.predict(X_train_resampled)\n",
    "y_hat_test = svcmodel.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train_resampled, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcmodel = SVC()\n",
    "param_grid = {\n",
    "    'C': [1,10,20],\n",
    "    'kernel': ['rbf','linear']\n",
    "}\n",
    "gs = GridSearchCV(svcmodel, param_grid)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_ = SVC(C=1, kernel='linear')\n",
    "svc_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "y_hat_train= svc_.predict(X_train)\n",
    "y_hat_test = svc_.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into X and y\n",
    "y=df['churn_Yes'].copy()\n",
    "\n",
    "# Define X\n",
    "\n",
    "X = df.drop(columns=['churn_Yes'], axis=1)\n",
    "\n",
    "\n",
    "# Split the data into a training and a test set and set stratify=y to help with imbalance data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,\n",
    "                                                 random_state=42,stratify=y)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling with LogesticREgression\n",
    "#create an instance and fit the model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "y_hat_train=logmodel.predict(X_train)\n",
    "y_hat_test = logmodel.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Gender column to numeric value\n",
    "#datset_churn['Gender'].unique() # Print unique values in the column\n",
    "df['gender_num'] = df['gender'].map( {'Female': 1, 'Male': 0} ).astype(int) #Map Categorical to Numerical Values\n",
    "# For Partner & Dependant , we created Family Column . Converting Family column to numeric value\n",
    "#datset_churn['Family'].unique() # Print unique values in the column\n",
    "df['family_num'] = df['partner'].map( {'Yes': 1, 'No': 0} ).astype(int) #Map Categorical to Numerical Values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'random_state': 0, 'n_jobs': 4, 'n_estimators': 5000, 'max_depth': 8}\n",
    "# One-hot encode\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "y=df['churn_Yes'].copy()\n",
    "\n",
    "# Define X\n",
    "\n",
    "x = df.drop(columns=['churn_Yes'], axis=1)\n",
    "\n",
    "# Fit RandomForest Classifier\n",
    "clf = RandomForestClassifier(**params)\n",
    "clf = clf.fit(x, y)\n",
    "\n",
    "# Plot features importances\n",
    "imp = pd.Series(data=clf.feature_importances_, index=x.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.title(\"Feature importance\")\n",
    "ax = sns.barplot(y=imp.index, x=imp.values, palette=\"Blues_d\", orient='h')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "y=df['churn_Yes'].copy()\n",
    "\n",
    "# Define X\n",
    "\n",
    "x = df.drop(columns=['churn_Yes'], axis=1)\n",
    "\n",
    "# Fit RandomForest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(x, y)\n",
    "\n",
    "# Plot features importances\n",
    "imp = pd.Series(data=clf.feature_importances_, index=x.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.title(\"Feature importance\")\n",
    "ax = sns.barplot(y=imp.index, x=imp.values, palette=\"Blues_d\", orient='h')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train_resampled, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"data/clean_churn.csv\")\n",
    "\n",
    "df2.replace(to_replace='Yes', value=1, inplace=True)\n",
    "df2.replace(to_replace='No', value=0, inplace=True)\n",
    "df2['gender'].replace(to_replace='Male', value=1, inplace=True)\n",
    "df2['gender'].replace(to_replace='Female', value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df2.iloc[:, :-3]\n",
    "df_cat = pd.get_dummies(new_df)\n",
    "df_cat.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn imports\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "#from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cat\n",
    "y = df2['churn'].values\n",
    "\n",
    "features = X.columns.values\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X))\n",
    "X.columns = features\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "pred_log_reg = log_reg.predict(X_test)\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, pred_log_reg), '\\n')\n",
    "\n",
    "# To get the weights of all the variables\n",
    "weights_LogReg = pd.Series(log_reg.coef_[0], index=X.columns.values)\n",
    "print(weights_LogReg)\n",
    "plt.figure(figsize=(6, 15))\n",
    "weights_LogReg.sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some variables are negatively correlated with the predicted variable (Churn), while some have positively. Negative correlation means that likeliness of churn decreases with that variable.\n",
    "\n",
    "Let me interpret some findings from above plot,\n",
    "\n",
    "As we have seen in our EDA, having a 2 month contract reduces chances of churn. 2 month contract along with tenure have the most negative relation with Churn as predicted by logistic regressions.\n",
    "Total charges, monthly contracts, fibre optic internet services and seniority can lead to higher churn rates. This is interesting because although fibre optic services are faster, customers are likely to churn because of it.\n",
    "I don't understad why this is happening.\n",
    "\n",
    "Till the time let's have a look at other algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000,\n",
    "                            oob_score = True,\n",
    "                            n_jobs = -1,\n",
    "                            random_state =50,\n",
    "                            max_features = \"auto\",\n",
    "                            max_leaf_nodes = 30)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "pred_rf = rf.predict(X_test)\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, pred_rf), '\\n')\n",
    "importances = rf.feature_importances_\n",
    "weights_RanFor = pd.Series(importances,\n",
    "                 index=X.columns.values)\n",
    "print(weights_RanFor)\n",
    "plt.figure(figsize=(6, 15))\n",
    "weights_RanFor.sort_values().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From random forest algorithm, monthly contract, tenure and total charges are the most important predictor variables to predict churn.\n",
    "The results from random forest are very similar to that of the logistic regression and in line to what we had expected from our EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AdaB = AdaBoostClassifier()\n",
    "model_AdaB.fit(X_train,y_train)\n",
    "preds_adaB = model_AdaB.predict(X_test)\n",
    "metrics.accuracy_score(y_test, preds_adaB)\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, preds_adaB), '\\n')\n",
    "importances = model_AdaB.feature_importances_\n",
    "weights_AdaB = pd.Series(importances,\n",
    "                 index=X.columns.values)\n",
    "print(weights_AdaB)\n",
    "plt.figure(figsize=(6, 15))\n",
    "weights_RanFor.sort_values().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC(kernel='linear') \n",
    "model_svm.fit(X_train, y_train)\n",
    "pred_svm = model_svm.predict(X_test)\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, pred_svm), '\\n')\n",
    "\n",
    "feature_importance = list(zip(model_svm.coef_[0], X.columns.values))\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With SVM-Linear Kernel, I am able to achieve the slightly higher than all accuracy on test data to almost 80.19%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "#from io import StringIO\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "clf= DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_hat_test = clf.predict(X_test)\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,\n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = df[X_train].columns)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_png('churn.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install sklearn.externals.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn==0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertin the predictor variable in a binary numeric variable\n",
    "df['churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "df['churn'].replace(to_replace='No',  value=0, inplace=True)\n",
    "\n",
    "#Let's convert all the categorical variables into dummy variables\n",
    "df_dummies = pd.get_dummies(df)\n",
    "df_dummies.head()\n",
    "\n",
    "# We will use the data frame where we had created dummy variables\n",
    "y = df_dummies['churn'].values\n",
    "X = df_dummies.drop(columns = ['churn'])\n",
    "\n",
    "# Scaling all the variables to a range of 0 to 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "features = X.columns.values\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X))\n",
    "X.columns = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train & Test Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "result = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "prediction_test = model.predict(X_test)\n",
    "# Print the prediction accuracy\n",
    "print (metrics.accuracy_score(y_test, prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "y_hat_train=model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate predictions\n",
    "print('-'*40)\n",
    "print('Accuracy score for Training Dataset = ', accuracy_score(y_train, y_hat_train))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#scale numeric features \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "# Scale the train and test data\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 41)\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train,y_train)\n",
    "X_train_resampled = pd.DataFrame(data=X_train_resampled,columns=columns )\n",
    "y_train_resampled = pd.DataFrame(data=y_train_resampled,columns=[\"churn\"])\n",
    "# we can Check the numbers of our data \n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train) \n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df = pd.read_csv(\"data/clean_churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:16].values # Feature Variable\n",
    "y = df.iloc[:,16].values # Target Variable\n",
    "\n",
    "#Dividing data into test & train splitting 70% data for training anf 30% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a list of all classifiers\n",
    "classifier_model = [LogisticRegression(),KNeighborsClassifier(),GaussianNB(),SVC(),DecisionTreeClassifier(),RandomForestClassifier(), SGDClassifier(), AdaBoostClassifier()]\n",
    "\n",
    "# Creating empty list to store the performance details\n",
    "classifier_model_list= []\n",
    "classifier_accuracy_test = []\n",
    "classifier_accuracy_train = []\n",
    "f1score = []\n",
    "precisionscore = []\n",
    "recallscore = []\n",
    "avg_pre_rec_score = []\n",
    "cv_score = []\n",
    "\n",
    "for classifier_list in classifier_model:\n",
    "    classifier = classifier_list\n",
    " \n",
    "    # Fitting the training set into classification model\n",
    "    classifier.fit(X_train,y_train)\n",
    "    \n",
    "    # Predicting the output on test datset\n",
    "    y_pred_test = classifier.predict(X_test)    \n",
    "    score_test = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Predicting the output on training datset\n",
    "    y_pred_train = classifier.predict(X_train) \n",
    "    score_train = accuracy_score(y_train, y_pred_train)\n",
    "    \n",
    "    # Cross Validation Score on training test\n",
    "    scores = cross_val_score(classifier, X_train,y_train, cv=10)\n",
    "    cv_score.append(scores.mean())\n",
    "    \n",
    "    #Keeping the model and accuracy score into a list\n",
    "    classifier_model_list.append(classifier_list.__class__.__name__)\n",
    "    classifier_accuracy_test.append(round(score_test,4))\n",
    "    classifier_accuracy_train.append(round(score_train,4))\n",
    "    \n",
    "    #Precision, Recall and F1 score\n",
    "    f1score.append(f1_score(y_test, y_pred_test))\n",
    "    precisionscore.append(precision_score(y_test, y_pred_test))\n",
    "    recallscore.append(recall_score(y_test, y_pred_test))\n",
    "    \n",
    "    #Calculating Average Precision Recall Score\n",
    "    try:\n",
    "        y_pred_score = classifier.decision_function(X_test)\n",
    "    except:\n",
    "        y_pred_score = classifier.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    from sklearn.metrics import average_precision_score\n",
    "    average_precision = average_precision_score(y_test, y_pred_score)\n",
    "    avg_pre_rec_score.append(average_precision)\n",
    "    \n",
    "    \n",
    "    #Confusion Matrix\n",
    "    plot_confusion_matrix(classifier_list.__class__.__name__, y_test, y_pred_test)\n",
    "    plot_prec_rec_curve(classifier_list.__class__.__name__, y_test, y_pred_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
